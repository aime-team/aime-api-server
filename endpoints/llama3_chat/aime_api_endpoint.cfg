# AIME API Endpoint Configuration File
#
# Copyright (c) AIME GmbH and affiliates. Find more info at https://www.aime.info/api
#
# This software may be used and distributed according to the terms of the MIT LICENSE

[ENDPOINT]
title = "LLama 3.3 Chat"
name = "llama3_chat"
description = "Llama 3.3 Instruct Chat example API"
methods = ["GET", "POST"]
version = 2

[WORKER]
job_type = "llama3"
auth_key = "5b07e305b50505ca2b3284b4ae5f65d1"

[CLIENTS]
client_request_limit = 0
provide_worker_meta_data = true	# default is false


# client authorization and authentication method (overwrites the value of server configuration)

# Available authentication: None, User, IP, Pubkey
authentication = "User"

# Available authorization: None, Key
authorization = "Key"
authorization_keys = { "aime" = "6a17e2a5b70603cb1a3294b4a1df67da" }

[SESSION]
# variables that should be kept in the session between calls and provided to the worker as additional inputs

[INPUTS]
prompt_input.type = "string"
prompt_input.default = ""
prompt_input.required = false

chat_context.type = "json"
chat_context.default = ""
chat_context.required = false

top_k.type = "integer"
top_k.minimum = 1
top_k.maximum = 1000
top_k.default = 40

top_p.type = "float"
top_p.minimum = 0.0
top_p.maximum = 1.0
top_p.default = 0.9

temperature.type = "float"
temperature.minimum = 0.0
temperature.maximum = 1.0
temperature.default = 0.8

max_gen_tokens.type = "integer"
max_gen_tokens.default = 2000

[OUTPUTS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }
model_name = { type = "string" }
max_seq_len = { type = "integer" }
current_context_length = { type = "integer" }
error = { type = "string" }

[PROGRESS]

    [PROGRESS.OUTPUTS]
    text = { type = "string" }
    num_generated_tokens = { type = "integer" }
    current_context_length = { type = "integer" }

[STATIC]
'/llama3-chat/' = { file = 'index.html' }
'/llama3_chat.html' = { file = 'index.html' }
'/llama3-chat/static/js/tailwind.js' = { file = '../../frontend/static/vendor/tailwind/tailwind_335_plugin_forms.min.js' }
'/llama3-chat/static/js/highlight.js' = { file = '../../frontend/static/vendor/highlight/highlight.min.js' }
'/llama3-chat/static/js/main.js' = { file = 'static/js/main.js' }
'/llama3-chat/static/css/style.css' = { file = 'static/css/style.css' }
'/llama3-chat/static/css/highlight.css' = { file = '../../frontend/static/vendor/highlight/styles/github.min.css' }
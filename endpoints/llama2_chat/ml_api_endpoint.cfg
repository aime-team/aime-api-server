# AIME ML API Endpoint Configuration File

[ENDPOINT]
title = "LLama 2 Chat"
name = "llama2_chat"
description = "LLama 2 Chat example API"
methods = "GET, POST"
version = 0
include_worker_meta_data = true
client_request_limit = 0

[WORKER]
job_type = "llama2"
auth_key = "5b07e305b50505ca2b3284b4ae5f65d1"

[INPUTS]
text.type = "string"
text.default = ""
text.required = true

seed.type = "integer"
seed.default = 1234

top_k.type = "integer"
top_k.minimum = 1
top_k.maximum = 1000
top_k.default = 40

top_p.type = "float"
top_p.minimum = 0.0
top_p.maximum = 1.0
top_p.default = 0.9

temperature.type = "float"
temperature.minimum = 0.0
temperature.maximum = 1.0
temperature.default = 0.8

[SESSION]
# variables that should be kept in the session between calls and provided to the worker as additional inputs

[PROGRESS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }

[OUTPUTS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }

[HTML]
'/llama2-chat/' = { file = 'index.html' }
'/llama2_chat.html' = { file = 'index.html' }
'/llama2-chat/static/js/tailwind.js' = { file = '../../frontend/static/vendor/tailwind/tailwind_335_plugin_forms.min.js' }
'/llama2-chat/static/js/highlight.js' = { file = '../../frontend/static/vendor/highlight/highlight.min.js' }
'/llama2-chat/static/js/main.js' = { file = 'static/js/main.js' }
'/llama2-chat/static/css/style.css' = { file = 'static/css/style.css' }
'/llama2-chat/static/css/highlight.css' = { file = '../../frontend/static/vendor/highlight/styles/github.min.css' }

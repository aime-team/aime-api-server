# AIME ML API Endpoint Configuration File

[ENDPOINT]
title = "LLama 2 Chat"
name = "llama2_chat"
description = "LLama 2 Chat example API"
methods = "GET, POST"
version = 1

[WORKER]
job_type = "llama2"
auth_key = "5b07e305b50505ca2b3284b4ae5f65d1"

[CLIENTS]
client_request_limit = 0
provide_worker_meta_data = true	# default is false
# client default authorization and authentication method (to overwrite the value of server configuration)
# Available authentification: None, User, IP, Pubkey
# default_authentification = "User"
# Available authorization: None, Key
# default_authorization = "Key"
# default_authorization_keys = { "aime" = "6a17e2a5b70603cb1a3294b4a1df67da" }

[SESSION]
# variables that should be kept in the session between calls and provided to the worker as additional inputs

[INPUTS]
text.type = "string"
text.default = ""
text.required = true

top_k.type = "integer"
top_k.minimum = 1
top_k.maximum = 1000
top_k.default = 40

top_p.type = "float"
top_p.minimum = 0.0
top_p.maximum = 1.0
top_p.default = 0.9

temperature.type = "float"
temperature.minimum = 0.0
temperature.maximum = 1.0
temperature.default = 0.8

[OUTPUTS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }
model_name = { type = "string" }


[PROGRESS]

    [PROGRESS.OUTPUTS]
    text = { type = "string" }
    num_generated_tokens = { type = "integer" }

[STATIC]
'/llama2-chat/' = { file = 'index.html' }
'/llama2_chat.html' = { file = 'index.html' }
'/llama2-chat/static/js/tailwind.js' = { file = '../../frontend/static/vendor/tailwind/tailwind_335_plugin_forms.min.js' }
'/llama2-chat/static/js/highlight.js' = { file = '../../frontend/static/vendor/highlight/highlight.min.js' }
'/llama2-chat/static/js/main.js' = { file = 'static/js/main.js' }
'/llama2-chat/static/css/style.css' = { file = 'static/css/style.css' }
'/llama2-chat/static/css/highlight.css' = { file = '../../frontend/static/vendor/highlight/styles/github.min.css' }

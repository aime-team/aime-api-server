# AIME Model API Endpoint Configuration File

[ENDPOINT]
title = "LLama Chat"
name = "llama_chat"
description = "LLama Chat example API"
methods = "GET, POST"
version = 0

[WORKER]
job_type = "llama"
auth_key = "5b07e305b50505ca2b3284b4ae5f65d1"

[INPUTS]
text.type = "string"
text.default = ""
text.required = true

seed.type = "integer"
seed.default = 1234

top_k.type = "integer"
top_k.minimum = 1
top_k.maximum = 1000
top_k.default = 40

top_p.type = "float"
top_p.minimum = 0.0
top_p.maximum = 1.0
top_p.default = 0.9

temperature.type = "float"
temperature.minimum = 0.0
temperature.maximum = 1.0
temperature.default = 0.8

[SESSION]
# variables that should be kept in the session between calls and provided to the worker as additional inputs

[PROGRESS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }

[OUTPUTS]
text = { type = "string" }
num_generated_tokens = { type = "integer" }

[HTML]
'/llama_chat.html' = { file = './endpoints/llama_chat/llama_chat.html' }
'/llama_chat.css' = { file = './endpoints/llama_chat/llama_chat.css' }
